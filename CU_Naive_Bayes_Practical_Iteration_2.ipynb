{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 548C-3498\n",
      "\n",
      " Directory of C:\\Users\\ADMIN\\Downloads\n",
      "\n",
      "03/01/2021  12:04 PM    <DIR>          .\n",
      "03/01/2021  12:04 PM    <DIR>          ..\n",
      "03/01/2021  10:22 AM    <DIR>          .ipynb_checkpoints\n",
      "01/24/2021  11:19 AM           462,623 1. Weather Data.csv\n",
      "02/16/2021  06:26 PM            62,218 16feb (1).ipynb\n",
      "02/25/2021  10:15 PM            18,811 1810992046-SATYAM.docx\n",
      "01/23/2021  04:56 PM           136,976 1810992046-SATYAM-converted.pdf\n",
      "01/22/2021  01:40 PM            11,864 22012021 - Introduction to Statistic lat.ipynb\n",
      "01/26/2021  02:14 PM         1,599,897 25012021 - Screenshots.zip\n",
      "02/04/2021  09:58 AM             4,756 Advertising.csv\n",
      "01/15/2021  09:51 PM            35,262 akanksha_img (1).jpg\n",
      "01/15/2021  09:51 PM            35,262 akanksha_img.jpg\n",
      "01/09/2021  01:02 AM       479,396,152 Anaconda3-2020.11-Windows-x86_64.exe\n",
      "01/23/2021  03:34 PM         3,189,712 AnyDesk.exe\n",
      "01/20/2021  10:04 AM             1,905 archive (1).zip\n",
      "01/20/2021  10:05 AM             1,905 archive (2).zip\n",
      "01/20/2021  10:05 AM             1,905 archive (3).zip\n",
      "02/11/2021  09:24 PM    <DIR>          archive (4)\n",
      "02/11/2021  09:21 PM           199,644 archive (4).zip\n",
      "01/18/2021  04:37 PM            11,514 archive.zip\n",
      "02/17/2021  09:44 AM           439,496 att 17.pdf\n",
      "02/27/2021  11:22 AM            23,329 attandance 27 feb.xlsx\n",
      "02/17/2021  11:59 AM            58,661 Attendance of Imarticus Students of Batch 2018 - Batch 3.pdf\n",
      "01/28/2021  10:02 PM            11,120 BA.xlsx\n",
      "01/09/2021  05:02 AM               920 Bank_Account_Details.csv\n",
      "02/11/2021  09:23 PM           938,020 Bengaluru_House_Data (1).csv\n",
      "02/11/2021  09:23 PM           938,020 Bengaluru_House_Data (2).csv\n",
      "02/11/2021  09:22 PM           938,020 Bengaluru_House_Data.csv\n",
      "01/24/2021  01:23 PM         1,232,960 BlueStacksInstaller_4.260.0.1032_native_f2a73974642357a52d7a7fbcee15b50f_R2FyZW5hIEZyZWUgRmlyZS1OZXcgQmVnaW5uaW5n.exe\n",
      "01/23/2021  03:24 PM            61,549 Campus SDE JD.pdf\n",
      "02/26/2021  03:40 PM           125,204 cancer (1).csv\n",
      "02/27/2021  02:39 PM           734,203 cancer prediction Project.ipynb\n",
      "02/26/2021  03:37 PM           125,204 cancer.csv\n",
      "02/26/2021  12:30 PM         3,844,210 census_income (1).csv\n",
      "02/12/2021  12:49 PM         3,844,210 census_income.csv\n",
      "02/22/2021  01:35 PM            43,133 CU_Decision_tree_Training.ipynb\n",
      "02/26/2021  12:17 PM            51,094 CU_KNN_Classroom_practice.ipynb\n",
      "02/19/2021  12:49 PM           193,487 CU_Logistics_Regression_Training_iteration_1.ipynb\n",
      "02/20/2021  12:01 AM           318,078 CU_Logistics_Regression_Training_iteration_2.ipynb\n",
      "02/22/2021  12:14 PM           346,929 CU_Logistics_Regression_Training_iteration_3.ipynb\n",
      "03/01/2021  12:00 PM            15,391 CU_Naive_Bayes_Practical_Iteration_1 (1).ipynb\n",
      "03/01/2021  10:52 AM            26,177 CU_Naive_Bayes_Practical_Iteration_1.ipynb\n",
      "03/01/2021  12:04 PM            32,774 CU_Naive_Bayes_Practical_Iteration_2.ipynb\n",
      "02/21/2021  07:15 PM           444,529 CU_Visulization_Exercise.ipynb\n",
      "01/13/2021  10:26 AM            16,558 Customer.csv\n",
      "01/23/2021  03:47 PM         4,342,633 Data_v1.zip\n",
      "01/18/2021  05:02 PM           603,290 Day3-np-pd (1).ipynb\n",
      "01/18/2021  05:02 PM           603,290 Day3-np-pd (2).ipynb\n",
      "01/18/2021  05:03 PM           603,290 Day3-np-pd (3).ipynb\n",
      "01/18/2021  05:02 PM           603,290 Day3-np-pd.ipynb\n",
      "01/20/2021  01:33 PM           626,454 Day4-pd-plt.ipynb\n",
      "01/10/2021  02:15 AM               196 dep.sql\n",
      "01/13/2021  10:27 AM            13,575 Employee_Details.csv\n",
      "01/13/2021  10:27 AM             2,576 employee_manages_shipment.csv\n",
      "01/13/2021  11:59 AM            15,928 Exam Paper.docx\n",
      "01/13/2021  12:22 PM            15,192 Exam_ Paper.docx\n",
      "01/19/2021  12:42 PM             1,102 gas_prices.csv\n",
      "02/16/2021  01:06 PM           656,042 HousePrices (1).csv\n",
      "02/21/2021  07:09 PM           656,042 HousePrices (2).csv\n",
      "02/16/2021  01:06 PM           656,042 HousePrices.csv\n",
      "02/11/2021  09:09 PM    <DIR>          house-prices-advanced-regression-techniques\n",
      "02/11/2021  08:59 PM           203,809 house-prices-advanced-regression-techniques.zip\n",
      "02/11/2021  08:54 PM           460,676 housetrain.csv\n",
      "01/13/2021  01:03 PM            20,252 Inclass_ SQL.docx\n",
      "01/13/2021  12:58 PM             8,601 Inclass_exercise(questions) (1).sql\n",
      "01/13/2021  12:58 PM             8,601 Inclass_exercise(questions) (2).sql\n",
      "01/13/2021  01:05 PM             4,158 Inclass_exercise(questions) (3).sql\n",
      "01/13/2021  12:45 PM             4,158 Inclass_exercise(questions).sql\n",
      "01/09/2021  06:05 AM         1,321,688 installbackupandsync.exe\n",
      "01/22/2021  01:41 PM             2,598 Introduction to Statistics\n",
      "02/25/2021  10:17 PM            83,853 Job Description Chitkara.pdf\n",
      "02/16/2021  01:02 PM            14,653 Linear_regression_Advertising_Basic.ipynb\n",
      "02/16/2021  12:58 PM         2,435,567 Linear_regression_Advertising_Complete_training (1).ipynb\n",
      "02/16/2021  05:07 PM            29,519 linreg_1st_iteration.ipynb\n",
      "02/21/2021  06:46 PM            83,696 LogisticRegression_TakeHomeQuestions.ipynb\n",
      "01/13/2021  10:27 AM             5,406 Membership.csv\n",
      "02/28/2021  05:34 PM           948,266 MuskaanChauhancancerpredictionproject.ipynb\n",
      "01/09/2021  12:12 AM       424,873,984 mysql-installer-community-8.0.22.0.msi\n",
      "02/04/2021  06:03 PM           180,507 OLS_Part_1.ipynb\n",
      "01/25/2021  02:54 PM               470 Orders.csv\n",
      "01/13/2021  10:27 AM            14,842 Payment_Details.csv\n",
      "02/16/2021  01:04 PM           485,831 ProblemStatement_LinearRegOLS.pdf\n",
      "01/13/2021  11:46 AM           211,234 Project _logistics.docx\n",
      "02/26/2021  03:31 PM         1,021,072 Project Attrition_ensemble_iteration_3.ipynb\n",
      "02/25/2021  10:35 PM         1,010,110 Project Attrition_Random_Forest_iteration_1.ipynb\n",
      "02/26/2021  10:37 PM         1,030,955 Project Attrition_Random_Forest_iteration_2.ipynb\n",
      "01/13/2021  11:27 AM           211,128 Project logistics.docx\n",
      "01/13/2021  11:13 AM            38,636 Project(SQL).doc\n",
      "01/13/2021  12:14 PM           211,234 Project_logistics.docx\n",
      "01/26/2021  02:20 PM            64,612 PythonIn-ClassExerciseAnswers (1).ipynb\n",
      "01/26/2021  02:15 PM            64,612 PythonIn-ClassExerciseAnswers.ipynb\n",
      "01/15/2021  01:43 PM            12,716 PythonIn-ClassExerciseQuestions (1).ipynb\n",
      "01/21/2021  11:30 AM            38,127 PythonIn-ClassExerciseQuestions (2).ipynb\n",
      "01/21/2021  09:42 AM            12,716 PythonIn-ClassExerciseQuestions (3).ipynb\n",
      "01/15/2021  01:38 PM            12,716 PythonIn-ClassExerciseQuestions.ipynb\n",
      "01/21/2021  01:26 PM             9,617 PythonProgrammingExamAnswers.ipynb\n",
      "01/21/2021  12:34 PM           392,959 PythonProgrammingExamQuestions.pdf\n",
      "01/21/2021  01:26 PM             9,617 pyton_exam_paper.txt\n",
      "01/25/2021  05:18 PM            13,348 retail-queries.docx\n",
      "01/25/2021  02:54 PM               177 Salesman.csv\n",
      "02/24/2021  07:48 AM           400,162 Satyam_DataVisualization random forest tree (1).ipynb\n",
      "02/24/2021  10:29 AM           406,776 Satyam_DataVisualization random forest tree.ipynb\n",
      "01/21/2021  05:39 PM            18,105 SATYAM_RESUME (1).docx\n",
      "01/21/2021  06:11 PM            18,177 SATYAM_RESUME.docx\n",
      "01/21/2021  05:40 PM           120,445 SATYAM_RESUME-converted.pdf\n",
      "01/24/2021  11:50 PM    <DIR>          sdd\n",
      "01/13/2021  10:27 AM            19,657 Shipment_Details.csv\n",
      "01/25/2021  04:12 PM           865,671 Shortlisted Students List for PPT and Test.pdf\n",
      "01/21/2021  04:54 PM            24,279 Single-Page-Resume.docx\n",
      "01/09/2021  06:09 AM    <DIR>          sql dataset\n",
      "01/25/2021  02:54 PM           304,968 SQL Exam Paper.pdf\n",
      "01/13/2021  10:30 AM           521,699 SQL_ProblemStatement.pdf\n",
      "01/13/2021  10:39 AM         3,118,653 SQL_Student Notes.pdf\n",
      "01/13/2021  11:51 AM           304,968 SQLExamPaper.pdf\n",
      "02/01/2021  01:32 PM           515,942 StatisticsandProbabilityExamQuestions.pdf\n",
      "02/01/2021  10:02 AM            34,900 Statistics-InClass-Questions (1).ipynb\n",
      "02/01/2021  10:02 AM            34,900 Statistics-InClass-Questions.ipynb\n",
      "02/01/2021  02:02 PM            18,683 Statstics_Exam_solution.ipynb\n",
      "01/13/2021  10:27 AM             6,481 Status.csv\n",
      "01/18/2021  10:03 PM           704,138 TCS National Qualifier Test.html\n",
      "01/18/2021  10:03 PM    <DIR>          TCS National Qualifier Test_files\n",
      "01/23/2021  03:57 PM        29,285,264 TeamViewer_Setup.exe\n",
      "01/20/2021  10:05 AM             9,729 tips.csv\n",
      "01/28/2021  01:27 PM            60,302 titanic.csv\n",
      "01/08/2021  10:12 AM            13,186 Tools list and link (1).docx\n",
      "01/21/2021  11:41 AM         4,268,628 train (1).csv\n",
      "01/26/2021  02:19 PM         4,268,628 train (2).csv\n",
      "12/15/2019  09:33 PM           460,676 train.csv\n",
      "02/22/2021  01:03 PM            19,236 tree.dot\n",
      "02/22/2021  12:58 PM                 0 tree.png\n",
      "03/01/2021  10:00 AM       102,895,657 uci-news-aggregator.csv\n",
      "02/26/2021  01:05 PM           162,559 Untitled.ipynb\n",
      "02/23/2021  01:12 PM           227,977 WA_Fn-UseC_-HR-Employee-Attrition.csv\n",
      "01/24/2021  11:18 PM             2,710 Weather analysis.py\n",
      "01/24/2021  11:48 PM           173,564 WEATHER_ANALYSIS.ipynb\n",
      "03/04/2019  07:32 PM             1,026 Webp.net-compress-image (4).jpg\n",
      "01/22/2021  01:40 PM           184,841 Working.xlsx\n",
      "02/21/2021  05:33 PM            38,026 xAPI-Edu-Data.csv\n",
      "01/28/2021  04:33 PM            28,808 YouTubeDataAnalysisQuestions (1).ipynb\n",
      "02/13/2021  09:18 PM           206,339 YouTubeDataAnalysisQuestions (2).ipynb\n",
      "02/13/2021  09:18 PM           206,339 YouTubeDataAnalysisQuestions (3).ipynb\n",
      "01/26/2021  11:55 PM            44,678 YouTubeDataAnalysisQuestions.ipynb\n",
      "01/08/2021  11:10 PM            83,288 Zoom_cm_ds_mi%2Byt7L7BiMDcYX2QX8%2ByGxRh0L36XDBGiFaQ%4020yTmEGVXLxAJeG3_k53f92b25afdc04b8_.exe\n",
      "             135 File(s)  1,095,009,410 bytes\n",
      "               8 Dir(s)  158,517,608,448 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1  Fed official says weak data caused by weather,...   \n",
       "1   2  Fed's Charles Plosser sees high bar for change...   \n",
       "2   3  US open: Stocks fall after Fed official hints ...   \n",
       "3   4  Fed risks falling 'behind the curve', Charles ...   \n",
       "4   5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "2  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "3  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "4  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
       "0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('uci-news-aggregator.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    152469\n",
       "b    115967\n",
       "t    108344\n",
       "m     45639\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.CATEGORY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \" Hi Whats up ,# I am going to buy,$ Blackberry's Product by '2021'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" hi whats up ,# i am going to buy,$ blackberry's product by '2021'\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = data.lower()\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" hi whats up # i am going to buy,$ blackberry's product by 2021'\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = re.sub('\\s\\W', ' ', d1)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" hi whats up  i am going to buy, blackberry's product by 2021'\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = re.sub('\\W\\s', ' ', d2)\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" hi whats up i am going to buy, blackberry's product by 2021'\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4 = re.sub('\\s+', ' ', d3)\n",
    "d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular xpresssion (RE)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to normalize the text\n",
    "\n",
    "def normalize_text(s):\n",
    "    s = s.lower()\n",
    "    \n",
    "    # remove punctuation that is not word-internal (e.g., hyphens, apostrophes)\n",
    "    s = re.sub('\\s\\W',' ',s)\n",
    "    s = re.sub('\\W\\s',' ',s)\n",
    "    \n",
    "    # make sure we didn't introduce any double spaces\n",
    "    s = re.sub('\\s+',' ',s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEXT'] = [normalize_text(s) for s in df['TITLE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         fed official says weak data caused by weather ...\n",
       "1         fed's charles plosser sees high bar for change...\n",
       "2         us open stocks fall after fed official hints a...\n",
       "3         fed risks falling behind the curve' charles pl...\n",
       "4         fed's plosser nasty weather has curbed job growth\n",
       "                                ...                        \n",
       "422414    surgeons to remove 4-year-old's rib to rebuild...\n",
       "422415    boy to have surgery on esophagus after battery...\n",
       "422416    child who swallowed battery to have reconstruc...\n",
       "422417    phoenix boy undergoes surgery to repair throat...\n",
       "422418    phoenix boy undergoes surgery to repair throat...\n",
       "Name: TEXT, Length: 422419, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.fit_transform(df['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<422419x54637 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3747875 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         b\n",
       "1         b\n",
       "2         b\n",
       "3         b\n",
       "4         b\n",
       "         ..\n",
       "422414    m\n",
       "422415    m\n",
       "422416    m\n",
       "422417    m\n",
       "422418    m\n",
       "Name: CATEGORY, Length: 422419, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CATEGORY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(df['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316814, 54637)\n",
      "(105605, 54637)\n",
      "(316814,)\n",
      "(105605,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Machine Learning Model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265375692438805"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Accuracy by manual process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrix = metrics.confusion_matrix(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26238,   552,   437,  1888],\n",
       "       [  509, 36596,   233,   687],\n",
       "       [  421,   355, 10387,   194],\n",
       "       [ 1737,   470,   275, 24626]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets create a function to test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cat(title):\n",
    "    cat_names = {'b': \"Business\", 't': \"Technology\", 'e': \"Entertainment\", 'm': \"Mental Heath\"}\n",
    "    cod = nb.predict(vectorizer.transform([title]))\n",
    "    return cat_names[encoder.inverse_transform(cod)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology\n"
     ]
    }
   ],
   "source": [
    "print(pred_cat(\"\"\"I am salesman\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
